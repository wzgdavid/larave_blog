原来django中有5个表，
article_article
article_articleauthor
article_articlecategory
article_articlepic
article_articletype
看下来只要拷前三个表，拷到laravel中的表名为
article_article ---> article
article_articleauthor ---> article_author
article_articlecategory  --->  article_category

拷article表时，有些datetime_publish的时间是0001年，会出错，做一下修改
update article_article set datetime_publish =now()  where datetime_publish < now() - interval '10 years'

从postgres中导出数据到csv中
1----件文件，给权限
david@ubuntu:~$ vim limit.csv
david@ubuntu:~$ chmod 777 limit.csv
2----title中的;改成:(有;的标题在导出到csv中时会被拆分成两列)
update article_article set title =  'China’s Copycats: Online vs. Offline.' where id=7939;
update article_article set title =  'Web browsers used most in China: how this impacts online campaigns.' where id=7804;
update article_article set title =  'Web browsers used most in China: how this impacts online campaigns.' where id=7926;
update article_article set title =  'Douban.com: China’s Amazon/Digg Hybrid Social Media Network.' where id=7973;
update article_article set title ='“China average daily salary is RMB 111.99???”: Chinese netizens challenge government statistics.	' where id=8029;
update article_article set title =  'China Telecom: Becoming the telephone version of Google.' where id=8072;
update article_article set title =  'The Rich Tighten Pockets: Online Shopping is New Obsession' where id=8169;
update article_article set title =  'The Good, The Bad And The Foreigner: Learning To Accept Myself Through The Eyes Of Others.' where id=7541;
update article_article set title =  'Johnson & Johnson: Big girls don’t cry… or let their bones break.' where id=8066;
select * from article_article where title like '%;%';

2.5----除了以上情况，还有会多一列的row,这些row的id 8029 ,10691,  10099, 8810, 8936, 8939 , 10126 ,10128 ,10222 ,9217 ,9178

太多了，不列举了，什么情况？？
拷到mysql中后没影响的，但把t和f通过py脚本改掉之后，不行了
**想出个解决方法

3----超级用户postgres， 密码postgres 登录
运行sql
COPY (SELECT * FROM article_article limit 50) TO '/home/david/myfile.csv' WITH CSV HEADER;
4--把导出的csv文件的第一行（culomn名删了）

csv导入mysql
1----mysql 是从 /var/lib/mysql/blog （blog是数据库名）这个目录下读文件的，所以把csv放到此目录下
然后在mysql运行sql命令：
load data infile 'myfile.csv' 
into table blog.article
fields terminated by ',' optionally enclosed by '"' escaped by '"' 
lines terminated by '\n'; 

***问题
postgres中boolean是用true和false表示 （在csv中是t和f）
但mysql中是用1和0（tinyint）表示，直接导入的话在mysql中都是显示0
把t和f改成1和0
2----导入后用py脚本导入布尔值 


****when export from postgresql
0----  change some title with ';', (in csv if the title have a ';' it will be separate to two columns)
update article_article set title =  'China’s Copycats: Online vs. Offline.' where id=7939;
update article_article set title =  'Web browsers used most in China: how this impacts online campaigns.' where id=7804;
update article_article set title =  'Web browsers used most in China: how this impacts online campaigns.' where id=7926;
update article_article set title =  'Douban.com: China’s Amazon/Digg Hybrid Social Media Network.' where id=7973;
update article_article set title ='“China average daily salary is RMB 111.99???”: Chinese netizens challenge government statistics.	' where id=8029;
update article_article set title =  'China Telecom: Becoming the telephone version of Google.' where id=8072;
update article_article set title =  'The Rich Tighten Pockets: Online Shopping is New Obsession' where id=8169;
update article_article set title =  'The Good, The Bad And The Foreigner: Learning To Accept Myself Through The Eyes Of Others.' where id=7541;
update article_article set title =  'Johnson & Johnson: Big girls don’t cry… or let their bones break.' where id=8066;
select * from article_article where title like '%;%';
1----  need to login postgres by a root user, the username is postgres
2----  create the new csv file,and chmod 777 it
3----  run the sql below
COPY (SELECT * FROM article_article) TO '/home/david/xxx.csv' WITH CSV HEADER;
4----  delete the first line in the exported CSV file (the first line is column name, if not delete the line will be copied to mysql table)


****when import to mysql
1---- mysql read the file from folder /var/lib/mysql/databasename, so copy the CSV to /var/lib/mysql/databasename/xxx.csv
2---- run the sql in mysql
load data infile 'xxx.csv' 
into table databasename.article
fields terminated by ',' optionally enclosed by '"' escaped by '"' 
lines terminated by '\n'; 
3---- the boolean value in postgres is t and f,but in mysql is 1 and 0 (tinyint),it will not be transformed 	automaticly, so need do something to change the t and f to 1 and 0 in the CSV.
but modify the boolean in csv will make some column not correct.
my way is import the origin csv data first, then update the boolean values by a script(I write a py script)


用laravel的migrate

一些sql
#delete FROM blog.article where id>0;
看column是否对齐
select * FROM blog.article where id in (8029 ,10691,  10099, 8810, 8936, 8939 , 10126 ,10128 ,10222 ,9217 ,9178,7898,7899)
加add_to_sitemap列
alter table blog.article add column is_in_sitemap tinyint(1) default 0;
加proofread列  （语法检测）
alter table blog.article add column is_proofread tinyint(1) default 0;




 ForeignKey 问题(原来的expat 表格不遵守外键，先不管)
 migration 中 做修改， 以后再做的时候直接create中写
            $table->integer('category_id')->unsigned();
            $table->foreign('category_id')->references('id')->on('article_category');
            $table->integer('author_id')->unsigned();
            $table->foreign('author_id')->references('id')->on('article_author');
            $table->integer('user_id')->unsigned();
            $table->foreign('user_id')->references('id')->on('users');



